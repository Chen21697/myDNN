# Deep Neuron Network Implementation without Toolkit

## Structure:
1. Fully connected
2. One input layer
  - 1 neuron
3. Two hidden layer
  - 10 neurons for each
  - ***tanh*** as optimizer for each
4. One output layer
  - 1 neuron
5. Loss function
  - RMS
6. Epoch
  - 300

Put ***structure.py*** and ***training.py*** into the same directory. Run ***training.py*** and it will plot the model you get and also the tendency of loss for each epoch.
Adjust the layer structure in DNN class in ***structure.py*** if you tend to do it

I used this project to get familiar with the process of Backpropagation such as forward and backward Pass. This project is not completely done yet.
