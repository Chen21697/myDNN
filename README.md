# Deep Neuron Network Implementation without Toolkit

## Structure:
- Fully connected
- One input layer
  - 1 neuron
- Two hidden layer
  - 10 neurons for each
  - ***tanh*** as activation functions
- One output layer
  - 1 neuron
- Loss function
  - RMS
- Epoch
  - 300

Put ***structure.py*** and ***training.py*** into the same directory. Run ***training.py*** and it will plot the model you get and also the tendency of loss for each epoch.
Adjust the layer structure in DNN class in ***structure.py*** if you tend to do it

I used this project to get familiar with the process of Backpropagation such as forward and backward Pass. This project is not completely done yet.
